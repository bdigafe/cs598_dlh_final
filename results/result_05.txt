Age(Year)   Epochs	max_seq_len	    batch_size	attention_heads num_hidden_layers   hidden_size	    lr	        Best Acc
Yes 	    30	    256	            128	        12	                 6	            288	            3.00E-05	0.5179
-------------------------------------------------------------------------------------------------------------------------
Training model. This will take time...
/usr/local/lib/python3.10/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)
  next_m.mul_(beta1).add_(1 - beta1, grad)
epoch: 0	| Batches: 100	| Total samples: 12800	 |Loss: 4.173036320209503	| precision: 0.3299	| time: 90.22
epoch: 0	| Batches: 200	| Total samples: 25600	 |Loss: 3.9890609645843504	| precision: 0.3387	| time: 84.91
epoch: 0	| Batches: 300	| Total samples: 38400	 |Loss: 3.8348049306869507	| precision: 0.3604	| time: 84.07
epoch: 0	| Batches: 400	| Total samples: 51200	 |Loss: 3.6523276424407958	| precision: 0.3643	| time: 84.05
epoch: 0	| Batches: 426	| Total samples: 54498	 |Loss: 3.537033255283649	| precision: 0.3704	| time: 21.62
** ** * Saving fine - tuned model ** ** * 
epoch: 1	| Batches: 100	| Total samples: 12800	 |Loss: 3.4806970524787904	| precision: 0.3682	| time: 84.11
epoch: 1	| Batches: 200	| Total samples: 25600	 |Loss: 3.3854252576828	| precision: 0.3716	| time: 84.02
epoch: 1	| Batches: 300	| Total samples: 38400	 |Loss: 3.3084163522720336	| precision: 0.3743	| time: 83.95
epoch: 1	| Batches: 400	| Total samples: 51200	 |Loss: 3.2571898198127744	| precision: 0.3773	| time: 84.09
epoch: 1	| Batches: 426	| Total samples: 54498	 |Loss: 3.232458683160635	| precision: 0.3815	| time: 21.58
** ** * Saving fine - tuned model ** ** * 
epoch: 2	| Batches: 100	| Total samples: 12800	 |Loss: 3.178279094696045	| precision: 0.3828	| time: 83.82
epoch: 2	| Batches: 200	| Total samples: 25600	 |Loss: 3.1322914505004884	| precision: 0.3868	| time: 83.97
epoch: 2	| Batches: 300	| Total samples: 38400	 |Loss: 3.088214054107666	| precision: 0.3899	| time: 84.30
epoch: 2	| Batches: 400	| Total samples: 51200	 |Loss: 3.028865990638733	| precision: 0.3989	| time: 84.20
epoch: 2	| Batches: 426	| Total samples: 54498	 |Loss: 3.045081615447998	| precision: 0.3892	| time: 21.65
** ** * Saving fine - tuned model ** ** * 
epoch: 3	| Batches: 100	| Total samples: 12800	 |Loss: 2.980244324207306	| precision: 0.4020	| time: 83.90
epoch: 3	| Batches: 200	| Total samples: 25600	 |Loss: 2.948078441619873	| precision: 0.4053	| time: 84.26
epoch: 3	| Batches: 300	| Total samples: 38400	 |Loss: 2.936603262424469	| precision: 0.4041	| time: 83.99
epoch: 3	| Batches: 400	| Total samples: 51200	 |Loss: 2.8818159461021424	| precision: 0.4133	| time: 83.94
epoch: 3	| Batches: 426	| Total samples: 54498	 |Loss: 2.8874852382219753	| precision: 0.4106	| time: 21.69
** ** * Saving fine - tuned model ** ** * 
epoch: 4	| Batches: 100	| Total samples: 12800	 |Loss: 2.864401116371155	| precision: 0.4108	| time: 84.23
epoch: 4	| Batches: 200	| Total samples: 25600	 |Loss: 2.8270671939849854	| precision: 0.4161	| time: 84.05
epoch: 4	| Batches: 300	| Total samples: 38400	 |Loss: 2.8278652596473695	| precision: 0.4172	| time: 84.02
epoch: 4	| Batches: 400	| Total samples: 51200	 |Loss: 2.809308624267578	| precision: 0.4185	| time: 84.15
epoch: 4	| Batches: 426	| Total samples: 54498	 |Loss: 2.800772327643174	| precision: 0.4185	| time: 21.71
** ** * Saving fine - tuned model ** ** * 
epoch: 5	| Batches: 100	| Total samples: 12800	 |Loss: 2.7770060753822325	| precision: 0.4216	| time: 83.99
epoch: 5	| Batches: 200	| Total samples: 25600	 |Loss: 2.7392247676849366	| precision: 0.4277	| time: 84.03
epoch: 5	| Batches: 300	| Total samples: 38400	 |Loss: 2.735590696334839	| precision: 0.4253	| time: 83.95
epoch: 5	| Batches: 400	| Total samples: 51200	 |Loss: 2.716229043006897	| precision: 0.4255	| time: 84.15
epoch: 5	| Batches: 426	| Total samples: 54498	 |Loss: 2.6900229178942165	| precision: 0.4309	| time: 21.70
** ** * Saving fine - tuned model ** ** * 
epoch: 6	| Batches: 100	| Total samples: 12800	 |Loss: 2.6873435735702516	| precision: 0.4300	| time: 83.95
epoch: 6	| Batches: 200	| Total samples: 25600	 |Loss: 2.6918977332115173	| precision: 0.4321	| time: 84.12
epoch: 6	| Batches: 300	| Total samples: 38400	 |Loss: 2.6637918186187743	| precision: 0.4350	| time: 84.14
epoch: 6	| Batches: 400	| Total samples: 51200	 |Loss: 2.654075207710266	| precision: 0.4340	| time: 84.13
epoch: 6	| Batches: 426	| Total samples: 54498	 |Loss: 2.6313137457920956	| precision: 0.4424	| time: 21.70
** ** * Saving fine - tuned model ** ** * 
epoch: 7	| Batches: 100	| Total samples: 12800	 |Loss: 2.6306876802444457	| precision: 0.4384	| time: 84.07
epoch: 7	| Batches: 200	| Total samples: 25600	 |Loss: 2.623907136917114	| precision: 0.4415	| time: 84.17
epoch: 7	| Batches: 300	| Total samples: 38400	 |Loss: 2.6009824204444887	| precision: 0.4455	| time: 83.95
epoch: 7	| Batches: 400	| Total samples: 51200	 |Loss: 2.59964998960495	| precision: 0.4467	| time: 84.04
epoch: 7	| Batches: 426	| Total samples: 54498	 |Loss: 2.600201423351581	| precision: 0.4412	| time: 21.68
** ** * Saving fine - tuned model ** ** * 
epoch: 8	| Batches: 100	| Total samples: 12800	 |Loss: 2.5739510798454286	| precision: 0.4502	| time: 84.07
epoch: 8	| Batches: 200	| Total samples: 25600	 |Loss: 2.56537296295166	| precision: 0.4491	| time: 83.88
epoch: 8	| Batches: 300	| Total samples: 38400	 |Loss: 2.551297788619995	| precision: 0.4527	| time: 84.02
epoch: 8	| Batches: 400	| Total samples: 51200	 |Loss: 2.541713659763336	| precision: 0.4533	| time: 84.31
epoch: 8	| Batches: 426	| Total samples: 54498	 |Loss: 2.5189332503538866	| precision: 0.4586	| time: 21.67
** ** * Saving fine - tuned model ** ** * 
epoch: 9	| Batches: 100	| Total samples: 12800	 |Loss: 2.528912415504456	| precision: 0.4528	| time: 83.95
epoch: 9	| Batches: 200	| Total samples: 25600	 |Loss: 2.5075826239585877	| precision: 0.4587	| time: 84.04
epoch: 9	| Batches: 300	| Total samples: 38400	 |Loss: 2.5245231938362123	| precision: 0.4523	| time: 84.32
epoch: 9	| Batches: 400	| Total samples: 51200	 |Loss: 2.5059517002105713	| precision: 0.4586	| time: 84.25
epoch: 9	| Batches: 426	| Total samples: 54498	 |Loss: 2.4895704159369836	| precision: 0.4610	| time: 21.68
** ** * Saving fine - tuned model ** ** * 
epoch: 10	| Batches: 100	| Total samples: 12800	 |Loss: 2.4836620259284974	| precision: 0.4603	| time: 83.98
epoch: 10	| Batches: 200	| Total samples: 25600	 |Loss: 2.4718998789787294	| precision: 0.4628	| time: 84.13
epoch: 10	| Batches: 300	| Total samples: 38400	 |Loss: 2.4732755160331727	| precision: 0.4612	| time: 84.03
epoch: 10	| Batches: 400	| Total samples: 51200	 |Loss: 2.483298273086548	| precision: 0.4612	| time: 84.07
epoch: 10	| Batches: 426	| Total samples: 54498	 |Loss: 2.474130942271306	| precision: 0.4655	| time: 21.64
** ** * Saving fine - tuned model ** ** * 
epoch: 11	| Batches: 100	| Total samples: 12800	 |Loss: 2.4465079045295717	| precision: 0.4646	| time: 84.08
epoch: 11	| Batches: 200	| Total samples: 25600	 |Loss: 2.44701895236969	| precision: 0.4681	| time: 83.90
epoch: 11	| Batches: 300	| Total samples: 38400	 |Loss: 2.4527657079696654	| precision: 0.4661	| time: 83.87
epoch: 11	| Batches: 400	| Total samples: 51200	 |Loss: 2.4417506504058837	| precision: 0.4668	| time: 84.00
epoch: 11	| Batches: 426	| Total samples: 54498	 |Loss: 2.425594604932345	| precision: 0.4703	| time: 21.53
** ** * Saving fine - tuned model ** ** * 
epoch: 12	| Batches: 100	| Total samples: 12800	 |Loss: 2.4234109139442443	| precision: 0.4706	| time: 83.96
epoch: 12	| Batches: 200	| Total samples: 25600	 |Loss: 2.4094444346427917	| precision: 0.4715	| time: 84.03
epoch: 12	| Batches: 300	| Total samples: 38400	 |Loss: 2.4234771156311035	| precision: 0.4702	| time: 84.01
epoch: 12	| Batches: 400	| Total samples: 51200	 |Loss: 2.4015117859840394	| precision: 0.4719	| time: 84.00
epoch: 12	| Batches: 426	| Total samples: 54498	 |Loss: 2.3818867206573486	| precision: 0.4759	| time: 21.60
** ** * Saving fine - tuned model ** ** * 
epoch: 13	| Batches: 100	| Total samples: 12800	 |Loss: 2.3863648772239685	| precision: 0.4782	| time: 83.97
epoch: 13	| Batches: 200	| Total samples: 25600	 |Loss: 2.389418303966522	| precision: 0.4748	| time: 84.21
epoch: 13	| Batches: 300	| Total samples: 38400	 |Loss: 2.371860480308533	| precision: 0.4776	| time: 84.04
epoch: 13	| Batches: 400	| Total samples: 51200	 |Loss: 2.3627805495262146	| precision: 0.4807	| time: 84.04
epoch: 13	| Batches: 426	| Total samples: 54498	 |Loss: 2.386071260158832	| precision: 0.4785	| time: 21.58
** ** * Saving fine - tuned model ** ** * 
epoch: 14	| Batches: 100	| Total samples: 12800	 |Loss: 2.3535389137268066	| precision: 0.4804	| time: 83.83
epoch: 14	| Batches: 200	| Total samples: 25600	 |Loss: 2.3318348932266235	| precision: 0.4876	| time: 84.01
epoch: 14	| Batches: 300	| Total samples: 38400	 |Loss: 2.337410981655121	| precision: 0.4841	| time: 83.98
epoch: 14	| Batches: 400	| Total samples: 51200	 |Loss: 2.356055510044098	| precision: 0.4822	| time: 84.03
epoch: 14	| Batches: 426	| Total samples: 54498	 |Loss: 2.3529603481292725	| precision: 0.4801	| time: 21.57
** ** * Saving fine - tuned model ** ** * 
epoch: 15	| Batches: 100	| Total samples: 12800	 |Loss: 2.318110134601593	| precision: 0.4913	| time: 83.89
epoch: 15	| Batches: 200	| Total samples: 25600	 |Loss: 2.3278031277656557	| precision: 0.4876	| time: 84.16
epoch: 15	| Batches: 300	| Total samples: 38400	 |Loss: 2.3154523587226867	| precision: 0.4901	| time: 84.08
epoch: 15	| Batches: 400	| Total samples: 51200	 |Loss: 2.3234448504447935	| precision: 0.4888	| time: 84.00
epoch: 15	| Batches: 426	| Total samples: 54498	 |Loss: 2.301233410835266	| precision: 0.4942	| time: 21.57
** ** * Saving fine - tuned model ** ** * 
epoch: 16	| Batches: 100	| Total samples: 12800	 |Loss: 2.2960411286354065	| precision: 0.4946	| time: 83.94
epoch: 16	| Batches: 200	| Total samples: 25600	 |Loss: 2.2974306893348695	| precision: 0.4906	| time: 84.05
epoch: 16	| Batches: 300	| Total samples: 38400	 |Loss: 2.300859034061432	| precision: 0.4911	| time: 84.00
epoch: 16	| Batches: 400	| Total samples: 51200	 |Loss: 2.30182831287384	| precision: 0.4901	| time: 84.23
epoch: 16	| Batches: 426	| Total samples: 54498	 |Loss: 2.294093975654015	| precision: 0.4881	| time: 21.54
** ** * Saving fine - tuned model ** ** * 
epoch: 17	| Batches: 100	| Total samples: 12800	 |Loss: 2.281912610530853	| precision: 0.4938	| time: 83.97
epoch: 17	| Batches: 200	| Total samples: 25600	 |Loss: 2.2965381717681885	| precision: 0.4924	| time: 84.05
epoch: 17	| Batches: 300	| Total samples: 38400	 |Loss: 2.2904929232597353	| precision: 0.4921	| time: 84.11
epoch: 17	| Batches: 400	| Total samples: 51200	 |Loss: 2.2770792174339296	| precision: 0.4923	| time: 84.01
epoch: 17	| Batches: 426	| Total samples: 54498	 |Loss: 2.2812195924612193	| precision: 0.4947	| time: 21.55
** ** * Saving fine - tuned model ** ** * 
epoch: 18	| Batches: 100	| Total samples: 12800	 |Loss: 2.277925605773926	| precision: 0.4952	| time: 84.07
epoch: 18	| Batches: 200	| Total samples: 25600	 |Loss: 2.2597057151794435	| precision: 0.4977	| time: 84.05
epoch: 18	| Batches: 300	| Total samples: 38400	 |Loss: 2.2723666822910307	| precision: 0.4956	| time: 84.40
epoch: 18	| Batches: 400	| Total samples: 51200	 |Loss: 2.251596969366074	| precision: 0.4997	| time: 84.04
epoch: 18	| Batches: 426	| Total samples: 54498	 |Loss: 2.2797957750467153	| precision: 0.4933	| time: 21.58
** ** * Saving fine - tuned model ** ** * 
epoch: 19	| Batches: 100	| Total samples: 12800	 |Loss: 2.2580730319023132	| precision: 0.4993	| time: 84.00
epoch: 19	| Batches: 200	| Total samples: 25600	 |Loss: 2.248706588745117	| precision: 0.4996	| time: 84.08
epoch: 19	| Batches: 300	| Total samples: 38400	 |Loss: 2.2481689870357515	| precision: 0.5004	| time: 84.02
epoch: 19	| Batches: 400	| Total samples: 51200	 |Loss: 2.243086516857147	| precision: 0.5020	| time: 83.92
epoch: 19	| Batches: 426	| Total samples: 54498	 |Loss: 2.2296014382289004	| precision: 0.5006	| time: 21.62
** ** * Saving fine - tuned model ** ** * 
epoch: 20	| Batches: 100	| Total samples: 12800	 |Loss: 2.2355791091918946	| precision: 0.5021	| time: 84.04
epoch: 20	| Batches: 200	| Total samples: 25600	 |Loss: 2.2434488201141356	| precision: 0.5003	| time: 84.26
epoch: 20	| Batches: 300	| Total samples: 38400	 |Loss: 2.238528709411621	| precision: 0.5033	| time: 84.00
epoch: 20	| Batches: 400	| Total samples: 51200	 |Loss: 2.233419862985611	| precision: 0.5010	| time: 83.89
epoch: 20	| Batches: 426	| Total samples: 54498	 |Loss: 2.2433686623206506	| precision: 0.4963	| time: 21.60
** ** * Saving fine - tuned model ** ** * 
epoch: 21	| Batches: 100	| Total samples: 12800	 |Loss: 2.214466986656189	| precision: 0.5035	| time: 84.15
epoch: 21	| Batches: 200	| Total samples: 25600	 |Loss: 2.230367366075516	| precision: 0.5035	| time: 83.92
epoch: 21	| Batches: 300	| Total samples: 38400	 |Loss: 2.211120219230652	| precision: 0.5074	| time: 84.12
epoch: 21	| Batches: 400	| Total samples: 51200	 |Loss: 2.2426736640930174	| precision: 0.5015	| time: 83.89
epoch: 21	| Batches: 426	| Total samples: 54498	 |Loss: 2.2165225652547984	| precision: 0.5084	| time: 21.69
** ** * Saving fine - tuned model ** ** * 
epoch: 22	| Batches: 100	| Total samples: 12800	 |Loss: 2.2034100532531737	| precision: 0.5066	| time: 83.97
epoch: 22	| Batches: 200	| Total samples: 25600	 |Loss: 2.2220931208133696	| precision: 0.5033	| time: 84.06
epoch: 22	| Batches: 300	| Total samples: 38400	 |Loss: 2.2227029955387114	| precision: 0.5044	| time: 84.10
epoch: 22	| Batches: 400	| Total samples: 51200	 |Loss: 2.205805846452713	| precision: 0.5082	| time: 83.98
epoch: 22	| Batches: 426	| Total samples: 54498	 |Loss: 2.197507991240575	| precision: 0.5096	| time: 21.67
** ** * Saving fine - tuned model ** ** * 
epoch: 23	| Batches: 100	| Total samples: 12800	 |Loss: 2.2067348051071165	| precision: 0.5087	| time: 84.05
epoch: 23	| Batches: 200	| Total samples: 25600	 |Loss: 2.201450871229172	| precision: 0.5078	| time: 84.09
epoch: 23	| Batches: 300	| Total samples: 38400	 |Loss: 2.1969354474544525	| precision: 0.5070	| time: 84.16
epoch: 23	| Batches: 400	| Total samples: 51200	 |Loss: 2.1937113213539123	| precision: 0.5073	| time: 84.15
epoch: 23	| Batches: 426	| Total samples: 54498	 |Loss: 2.210419022119962	| precision: 0.5065	| time: 21.77
** ** * Saving fine - tuned model ** ** * 
epoch: 24	| Batches: 100	| Total samples: 12800	 |Loss: 2.1895901727676392	| precision: 0.5123	| time: 84.08
epoch: 24	| Batches: 200	| Total samples: 25600	 |Loss: 2.1778755164146424	| precision: 0.5116	| time: 84.13
epoch: 24	| Batches: 300	| Total samples: 38400	 |Loss: 2.204217290878296	| precision: 0.5084	| time: 84.04
epoch: 24	| Batches: 400	| Total samples: 51200	 |Loss: 2.16710107922554	| precision: 0.5128	| time: 83.89
epoch: 24	| Batches: 426	| Total samples: 54498	 |Loss: 2.178390159056737	| precision: 0.5130	| time: 21.66
** ** * Saving fine - tuned model ** ** * 
epoch: 25	| Batches: 100	| Total samples: 12800	 |Loss: 2.1869863724708556	| precision: 0.5118	| time: 84.03
epoch: 25	| Batches: 200	| Total samples: 25600	 |Loss: 2.1937474417686462	| precision: 0.5101	| time: 84.01
epoch: 25	| Batches: 300	| Total samples: 38400	 |Loss: 2.1673773884773255	| precision: 0.5129	| time: 84.02
epoch: 25	| Batches: 400	| Total samples: 51200	 |Loss: 2.1853107404708862	| precision: 0.5093	| time: 84.13
epoch: 25	| Batches: 426	| Total samples: 54498	 |Loss: 2.1981134231273947	| precision: 0.5113	| time: 21.64
** ** * Saving fine - tuned model ** ** * 
epoch: 26	| Batches: 100	| Total samples: 12800	 |Loss: 2.1718526136875154	| precision: 0.5160	| time: 84.04
epoch: 26	| Batches: 200	| Total samples: 25600	 |Loss: 2.1760781455039977	| precision: 0.5120	| time: 84.06
epoch: 26	| Batches: 300	| Total samples: 38400	 |Loss: 2.1583980667591094	| precision: 0.5139	| time: 83.94
epoch: 26	| Batches: 400	| Total samples: 51200	 |Loss: 2.172249916791916	| precision: 0.5137	| time: 84.01
epoch: 26	| Batches: 426	| Total samples: 54498	 |Loss: 2.141051164040199	| precision: 0.5145	| time: 21.74
** ** * Saving fine - tuned model ** ** * 
epoch: 27	| Batches: 100	| Total samples: 12800	 |Loss: 2.1801917219161986	| precision: 0.5128	| time: 84.03
epoch: 27	| Batches: 200	| Total samples: 25600	 |Loss: 2.1477257204055786	| precision: 0.5178	| time: 84.14
epoch: 27	| Batches: 300	| Total samples: 38400	 |Loss: 2.1647107148170472	| precision: 0.5128	| time: 84.05
epoch: 27	| Batches: 400	| Total samples: 51200	 |Loss: 2.152203359603882	| precision: 0.5150	| time: 83.97
epoch: 27	| Batches: 426	| Total samples: 54498	 |Loss: 2.111403222267444	| precision: 0.5245	| time: 21.67
** ** * Saving fine - tuned model ** ** * 
epoch: 28	| Batches: 100	| Total samples: 12800	 |Loss: 2.144141467809677	| precision: 0.5193	| time: 84.03
epoch: 28	| Batches: 200	| Total samples: 25600	 |Loss: 2.1628900039196015	| precision: 0.5151	| time: 84.07
epoch: 28	| Batches: 300	| Total samples: 38400	 |Loss: 2.146263459920883	| precision: 0.5160	| time: 84.07
epoch: 28	| Batches: 400	| Total samples: 51200	 |Loss: 2.1361247968673704	| precision: 0.5193	| time: 83.95
epoch: 28	| Batches: 426	| Total samples: 54498	 |Loss: 2.126878316585834	| precision: 0.5243	| time: 21.73
** ** * Saving fine - tuned model ** ** * 
epoch: 29	| Batches: 100	| Total samples: 12800	 |Loss: 2.1326479685306547	| precision: 0.5182	| time: 84.02
epoch: 29	| Batches: 200	| Total samples: 25600	 |Loss: 2.159923721551895	| precision: 0.5160	| time: 83.99
epoch: 29	| Batches: 300	| Total samples: 38400	 |Loss: 2.142332297563553	| precision: 0.5190	| time: 83.98
epoch: 29	| Batches: 400	| Total samples: 51200	 |Loss: 2.1390511453151704	| precision: 0.5179	| time: 84.09
epoch: 29	| Batches: 426	| Total samples: 54498	 |Loss: 2.1382039189338684	| precision: 0.5188	| time: 21.70
** ** * Saving fine - tuned model ** ** * 
Best accuracy: 0.5178527007985337