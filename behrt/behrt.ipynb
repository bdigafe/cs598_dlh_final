{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDIyndGVBJZh"
      },
      "source": [
        "### Project: Application of BERT to Electronic Health Records to predit the next diagnosis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qtTLL2DrBJZk"
      },
      "source": [
        "#### Define the source data\n",
        "In this section we the syntethic data obtained from the Medysin website. For this project, we use the outpatient data. The site also provided synthetic data for ICU. Download access was provided by the TA. Please check post # in campuswire. The data is available as a set of CSV files, each describing different aspects of EHR.\n",
        "\n",
        "**persons.csv**: List of patients.\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "**visit.occurence**: List of patients' visits and high level details of each visit. The visit id uniquely identifies each record. The patient id field defines the patient from the patients file.\n",
        "\n",
        "![image.png](attachment:image-2.png)\n",
        "\n",
        "**conditions_occurence**: List the disease occurrence (diagnoses) for each visit, which indirectly relates the patient.\n",
        "\n",
        "![image.png](attachment:image-3.png)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9SAOGkOIBJZl"
      },
      "source": [
        "#### Data entity diagram\n",
        "The following figure shows the entity-relationship of the three main data tables after removing data columns that are not useful for this project because they are not present (always blank) or have the same value for all the records.\n",
        "\n",
        "![image.png](attachment:image-2.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "local_mode = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCUA0c8cBgHD",
        "outputId": "9e8d6d80-f871-4a52-cc9e-fabf398b38eb"
      },
      "outputs": [],
      "source": [
        "if not local_mode:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "\n",
        "    !cp -r gdrive/MyDrive/behrt/data data/\n",
        "    !cp -r gdrive/MyDrive/behrt/commons commons/\n",
        "    !cp -r gdrive/MyDrive/behrt/models models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "IayjuaWgBJZm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pdb\n",
        "import sys\n",
        "import time\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import commons.utils as utils\n",
        "\n",
        "# set random seed for reproducibility\n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "os.environ['PYTHONASHSEED'] = str(seed)\n",
        "\n",
        "global_params = {\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'max_seq_len': 256,\n",
        "    'max_age' : 110,\n",
        "    'age_month' : 1,\n",
        "    'min_visit': 5,\n",
        "\n",
        "    'batch_size': 64, #128,\n",
        "    'num_epochs': 5,\n",
        "    'gradient_accumulation_steps': 1,\n",
        "    'training_sample': 1000,\n",
        "    \n",
        "    # Bert model parameters to fine-tune\n",
        "    'attention_heads': 6, #12,\n",
        "    'num_hidden_layers': 3, #6,\n",
        "    'hidden_size': 72 #288\n",
        "}\n",
        "\n",
        "optim_param = {\n",
        "    'lr': 3e-5,\n",
        "    'warmup_proportion': 0.1,\n",
        "    'weight_decay': 0.01\n",
        "}\n",
        "\n",
        "file_config = {\n",
        "    'vocab': ('C:/Birhanu/Education/UIL/cs598/Final/data/' if local_mode else 'data/') + 'condition_codes.pkl',\n",
        "    'data': ('C:/Birhanu/Education/UIL/cs598/Final/data/' if local_mode else 'data/') + 'conditions.pkl',\n",
        "    'ages': ('C:/Birhanu/Education/UIL/cs598/Final/data/' if local_mode else 'data/') + 'ages.pkl',\n",
        "    \n",
        "    'model_path': 'C:/Birhanu/Education/UIL/cs598/Final/saved_models/' if local_mode else 'data/',  # where to save model\n",
        "    'model_name': 'mlm128',  # model name\n",
        "    'log_file_name': 'log',  # log path\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v2r6vexFttq",
        "outputId": "3c9d914d-7a2f-49e9-e8a8-aa48d571b8c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(global_params[\"device\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AkM2z7YqH0K6"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt_kVGeZBJZo"
      },
      "source": [
        "#### Load pre-processed data\n",
        "Data has been pre-processed and saved as pkl file.\n",
        "\n",
        "- conditions_seqs = [pid, [conditions]]\n",
        "- condition_codes = [code, frequency_count]\n",
        "- ages = [pid, [age for each condition]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf_4wsLcBJZo",
        "outputId": "1f83167d-5f79-4b65-88d9-ff376d10a36b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Condition sequences: \n",
            "      pid                                         conditions\n",
            "0  176101  [1572199, SEP, 35207924, SEP, 35209141, SEP, 1...\n",
            "1  176102  [35207924, 35211387, SEP, 1569634, SEP, 157606...\n",
            "2  176103  [1570669, SEP, 1570669, SEP, 35208969, SEP, 35...\n",
            "3  176104  [35208969, SEP, 35208968, 35208969, SEP, 35208...\n",
            "4  176105  [1568078, 1569178, 1572190, 1572239, SEP, 1568...\n",
            "Age sequences:\n",
            "      pid                                               ages\n",
            "0  176101  [947, 947, 947, 947, 949, 949, 949, 949, 949, ...\n",
            "1  176102  [230, 230, 230, 262, 262, 263, 263, 267, 267, ...\n",
            "2  176103           [664, 664, 666, 666, 672, 672, 684, 684]\n",
            "3  176104  [623, 623, 623, 623, 623, 623, 623, 623, 625, ...\n",
            "4  176105  [683, 683, 683, 683, 683, 684, 684, 684, 689, ...\n",
            "Condition codes:\n",
            "  condition                                     condition_name  counts\n",
            "0     10851  Sprain of joints and ligaments of other parts ...    4323\n",
            "1     11803                Sprain of ligaments of lumbar spine    4293\n",
            "2   1567286                                       Other sepsis    3217\n",
            "3   1567391                Viral infection of unspecified site    4177\n",
            "4   1567392                                    Dermatophytosis    4198\n"
          ]
        }
      ],
      "source": [
        "# Load pickle files\n",
        "conditions_seqs = pickle.load(open(file_config[\"data\"], 'rb'))\n",
        "age_seqs = pickle.load(open(file_config[\"ages\"], 'rb'))\n",
        "condition_codes = pickle.load(open(file_config[\"vocab\"], 'rb'))\n",
        "\n",
        "print(f\"Condition sequences: \\n{conditions_seqs.head()}\")\n",
        "print(f\"Age sequences:\\n{age_seqs.head()}\")\n",
        "print(f\"Condition codes:\\n{condition_codes.head()}\")\n",
        "\n",
        "# convert to numpy array\n",
        "conditions_seqs = np.array(conditions_seqs[\"conditions\"])\n",
        "age_seqs = np.array(age_seqs[\"ages\"])\n",
        "\n",
        "# Keep only a small size for training\n",
        "if (global_params[\"training_sample\"] > 0):\n",
        "    conditions_seqs = conditions_seqs[:global_params[\"training_sample\"]]\n",
        "    age_seqs = age_seqs[:global_params[\"training_sample\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn4L91F9BJZp",
        "outputId": "b88d834e-4385-46f9-eee9-999e6d4f571a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of patients: 2000\n",
            "Max number of code sequences: 388\n",
            "Max number of age sequences: 388\n"
          ]
        }
      ],
      "source": [
        "# Get the max number of visits per patient for all patients\n",
        "max_code_seqs = np.max([len(seq) for seq in conditions_seqs])\n",
        "max_age_seqs = np.max([len(seq) for seq in age_seqs])\n",
        "\n",
        "# Inspect sequence data\n",
        "print(f\"Number of patients: {len(conditions_seqs)}\")\n",
        "print(f\"Max number of code sequences: {max_code_seqs}\")\n",
        "print(f\"Max number of age sequences: {max_age_seqs}\")\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Build ageVocab\n",
        "This allows conversion between a person's age to an index or an index to age."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "age2idx, idx2age = utils.age_vocab(max_age=110, mon=global_params[\"age_month\"])\n",
        "\n",
        "ageVocab = {\n",
        "    'token2idx': age2idx,\n",
        "    'idx2token': idx2age\n",
        "}\n",
        "\n",
        "assert ageVocab['token2idx'][\"30\"] == 32\n",
        "assert ageVocab['idx2token'][30] == \"28\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LbMHMCUBJZs"
      },
      "source": [
        "#### Build code from/to index vocab for condition codes\n",
        "The vocab will be used to convert from/to condition codes and indexes.\n",
        "All the diagnosis codes are loaded from the diag_codes.pkl file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLHZ-XR6BJZt",
        "outputId": "8dce8f14-778f-49c5-ee6a-6d18b449cb1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10851\n"
          ]
        }
      ],
      "source": [
        "conditionsVocab = utils.get_codes_vocab(file_config['vocab'])\n",
        "\n",
        "print(conditionsVocab['idx2token'][5])\n",
        "\n",
        "assert conditionsVocab['idx2token'][5] == \"10851\"\n",
        "assert conditionsVocab['token2idx'][\"10851\"] == 5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzuVtN-QBJZt"
      },
      "source": [
        "### View distribution of condition codes.\n",
        "We removed conditions with less than 3000 ocurrences but it is good to see the prevalence of the remaining conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSIB0ZzmCpEt",
        "outputId": "7fa81296-e337-45d2-da3d-1a15ee7cfbee"
      },
      "outputs": [],
      "source": [
        "if not local_mode:\n",
        "    %pip install mplcursors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "oG3EbfukBJZt",
        "outputId": "9373c516-9ceb-4238-d614-c5f60924575f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import mplcursors\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "scatter = ax.scatter(condition_codes.index, condition_codes[\"counts\"])\n",
        "\n",
        "mplcursor = mplcursors.cursor(scatter, hover=True)\n",
        "mplcursor.connect(\"add\", lambda sel: sel.annotation.set_text(\n",
        "    condition_codes[sel.target.index][\"condition\"]))\n",
        "\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoZN0AE7BJZv"
      },
      "source": [
        "### Create a collate function to flatten the diagnosis codes\n",
        "\n",
        "The seqs data has the following format: \n",
        "[pid, vid, [diagnosis codes]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "s-7Pm0UgBJZv"
      },
      "outputs": [],
      "source": [
        "class Collator:\n",
        "\n",
        "    def __call__(self, data):\n",
        "        \"\"\"\n",
        "            Arguments:\n",
        "                data: a list of samples fetched from 'MLMDataset'\n",
        "\n",
        "            Outputs:\n",
        "                code_seqs: a tensor of shape (# patients, len(condition_codes))\n",
        "                age_seqs: A tensor of shape(# patients, max_age)\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "collate_fn = Collator()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fv7Z3nHBJZv"
      },
      "source": [
        "### Define custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "eJiaH88IBJZw"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "class MLMDataset(Dataset):\n",
        "    \"\"\"\n",
        "        Dataloader for MLM task. \n",
        "        The input is a list of tokens specified by datafrmae and the output is a list of tokens with masking.\n",
        "        The output is used to train the model to predict the masked tokens.\n",
        "\n",
        "        The dataloaer will return the following:\n",
        "            code: list = list of tokens\n",
        "            age: list = list of age of the patient\n",
        "           \n",
        "            position: list = list of position indexes\n",
        "            segmentation: list = list of segment indexes\n",
        "            mask: list = list of mask indexes  (1 indicate the token is masked)\n",
        "            label: list = list of label indexes (the label is the index of the token in the original tokens)\n",
        "\n",
        "        the input dataframe must have the following columns:\n",
        "            code: list = list of tokens\n",
        "            age: list = list of age of the patient\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, code_seqs, age_seqs, token2idx, age2idx, max_len, code='code', age='age'):\n",
        "        self.max_len = max_len\n",
        "\n",
        "        self.code_seqs = code_seqs\n",
        "        self.age_seqs = age_seqs\n",
        "\n",
        "        self.token2idx = token2idx\n",
        "        self.age2idx = age2idx\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        return: age, code, position, segmentation, mask, label\n",
        "        \"\"\"\n",
        "\n",
        "        # extract data\n",
        "        code_tokens = self.code_seqs[index][(-self.max_len+1):]\n",
        "        age_tokens = self.age_seqs[index][(-self.max_len+1):]\n",
        "\n",
        "        # avoid data cut with first element to be 'SEP'\n",
        "        if code_tokens[0] != 'CLS':\n",
        "            code_tokens = np.append(np.array(['CLS']), code_tokens)\n",
        "            age_tokens = np.append(age_tokens[0], age_tokens)\n",
        "\n",
        "        # mask 0:len(code) to 1, padding to be 0\n",
        "        mask = np.ones(self.max_len)\n",
        "        mask[len(code_tokens):] = 0\n",
        "        num_tokens = len(code_tokens)\n",
        "\n",
        "        # Get index for Unknown symbol and Pad symbol\n",
        "        pad_symbol = self.token2idx.get('PAD')\n",
        "\n",
        "        # Pad age sequences\n",
        "        age_tokens = utils.seq_padding(age_tokens, self.max_len, token2idx=self.age2idx)\n",
        "\n",
        "        # Masking: get masked code and label. Token -> Index\n",
        "        out_tokens, label = utils.random_mask(code_tokens, token2idx=self.token2idx)\n",
        "        code_tokens = utils.seq_padding(code_tokens, self.max_len)\n",
        "\n",
        "        # get the number of masked tokens\n",
        "        #n_mask = (torch.tensor(label) != -1).sum().item()\n",
        "        #print(f\"Index: {index}, Total: {num_tokens}, Masked tokens: {n_mask}, Percentage: {n_mask/num_tokens*100:.2f}%\")\n",
        "\n",
        "        # Additinal embeddings Position and Segment)\n",
        "        position = utils.position_idx(code_tokens)\n",
        "        segment = utils.index_seg(code_tokens)\n",
        "\n",
        "        # Pad tokens and lables\n",
        "        out_tokens = utils.seq_padding(out_tokens, self.max_len, symbol=pad_symbol)\n",
        "        label = utils.seq_padding(label, self.max_len, symbol=-1)     \n",
        "\n",
        "        return  torch.LongTensor(out_tokens), \\\n",
        "                torch.LongTensor(age_tokens), \\\n",
        "                torch.LongTensor(position), \\\n",
        "                torch.LongTensor(segment), \\\n",
        "                torch.LongTensor(mask), \\\n",
        "                torch.LongTensor(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.code_seqs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2ooyo2FBJZx",
        "outputId": "e9d96302-47d7-4ba5-d325-e94b3d58b86a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length dataset: 2000\n",
            "\n",
            "UNK\n"
          ]
        }
      ],
      "source": [
        "\n",
        "token2idx = conditionsVocab[\"token2idx\"]\n",
        "age2idx = ageVocab[\"token2idx\"]\n",
        "\n",
        "dataset = MLMDataset(conditions_seqs, age_seqs, token2idx,age2idx, max_len=global_params['max_seq_len'])\n",
        "\n",
        "print(f\"Length dataset: {len(dataset)}\\n\")\n",
        "\n",
        "if (global_params[\"training_sample\"] > 0):\n",
        "    assert len(\n",
        "        dataset) == global_params[\"training_sample\"], \"The number of records is not correct\"\n",
        "else:\n",
        "    assert len(dataset) == 54498, \"The number of records is not correct\"\n",
        "\n",
        "print(conditionsVocab[\"idx2token\"][4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgGDNTlxBJZx",
        "outputId": "053e2209-b519-40d9-92b2-7e1440a52865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " tensor([  0, 254,   1, 133,   1, 133, 281, 133,   1, 133,   1, 133,   1, 133,\n",
            "          1, 133, 292,   1, 116, 133])\n",
            "\n",
            "Age:\n",
            "tensor([397, 397, 397, 411, 411, 412, 412, 412, 412, 412, 412, 412, 412, 412,\n",
            "        412, 412, 412, 412, 412, 412])\n",
            "\n",
            "Positions:\n",
            "tensor([0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 7, 8, 8])\n",
            "\n",
            "Segments:\n",
            "tensor([0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0])\n",
            "\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([-1, -1, -1, -1, -1, -1,  1, -1, -1, -1])\n",
            "0 == CLS\n",
            "1 == SEP\n",
            "2 == PAD\n",
            "3 == MASK\n",
            "4 == UNK\n",
            "tensor([  3, 238, 275,   1,  96,   1, 203,   1,  78, 163])\n"
          ]
        }
      ],
      "source": [
        "# Test batch data\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def inspect_batch():\n",
        "    dataset = MLMDataset(conditions_seqs, age_seqs, token2idx, age2idx, max_len=global_params['max_seq_len'])\n",
        "    train_loader = DataLoader(dataset=dataset, batch_size=global_params['batch_size'], shuffle=False)\n",
        "    loader_iter = iter(train_loader)\n",
        "    batch = next(loader_iter)\n",
        "\n",
        "    batch = tuple(t.to(global_params['device']) for t in batch)\n",
        "    input_ids, age_ids, posi_ids, segment_ids, attMask, masked_label = batch\n",
        "    \n",
        "    # Token codes\n",
        "    p = 10\n",
        "    print(f\"Input:\\n {input_ids[p, 0:20]}\\n\")\n",
        "    print(f\"Age:\\n{age_ids[p, 0:20]}\\n\")\n",
        "    print(f\"Positions:\\n{posi_ids[p, 0:20]}\\n\")\n",
        "    print(f\"Segments:\\n{segment_ids[p, 0:20]}\\n\")\n",
        "\n",
        "    print(attMask[p, 0:10])\n",
        "    print(masked_label[p, 0:10])\n",
        "\n",
        "    # Coditions vocab\n",
        "    for i in range(5):\n",
        "      print(f\"{i} == {conditionsVocab['idx2token'][i]}\")\n",
        "\n",
        "    # Display input ids for the 2nd record in the batch\n",
        "    print(input_ids[1, 0:10])\n",
        "\n",
        "inspect_batch()\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4Np8-oq3BJZy"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=global_params['batch_size'], shuffle=True)\n",
        "\n",
        "loader_iter = iter(train_loader)\n",
        "code_tokens, age_tokens, position, segment, mask, label = next(loader_iter)\n",
        "\n",
        "assert code_tokens.shape == (global_params['batch_size'], global_params['max_seq_len'])\n",
        "assert age_tokens.shape == (global_params['batch_size'], global_params['max_seq_len'])\n",
        "assert position.shape == (global_params['batch_size'], global_params['max_seq_len'])\n",
        "assert segment.shape == (global_params['batch_size'], global_params['max_seq_len'])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oks1uW0PBJZy"
      },
      "source": [
        "### Pre-taining BEHRT"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Define BERT model configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8u9Mihm3BJZy"
      },
      "outputs": [],
      "source": [
        "model_config = {\n",
        "    # number of disease + symbols for word embedding\n",
        "    'vocab_size': len(conditionsVocab['token2idx'].keys()),\n",
        "\n",
        "    # word embedding and seg embedding hidden size  \n",
        "    'hidden_size': global_params['hidden_size'],\n",
        "\n",
        "    # number of vocab for seg embedding\n",
        "    'seg_vocab_size': 2,  \n",
        "\n",
        "    # number of vocab for age embedding\n",
        "    'age_vocab_size': len(ageVocab['token2idx'].keys()),\n",
        "    \n",
        "    # maximum number of tokens\n",
        "    'max_position_embedding': global_params['max_seq_len'],\n",
        "\n",
        "    # dropout rate\n",
        "    'hidden_dropout_prob': 0.1, \n",
        "\n",
        "    # number of multi-head attention layers required\n",
        "    'num_hidden_layers': global_params['num_hidden_layers'] ,  \n",
        "\n",
        "    # number of attention heads\n",
        "    'num_attention_heads': global_params['attention_heads'], \n",
        "\n",
        "    # multi-head attention dropout rate\n",
        "    'attention_probs_dropout_prob': 0.1,  \n",
        "\n",
        "    # the size of the \"intermediate\" layer in the transformer encoder\n",
        "    'intermediate_size': 512,\n",
        "\n",
        "    # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
        "    'hidden_act': 'gelu',\n",
        "\n",
        "    # The layer normalization epsilon\n",
        "    'initializer_range': 0.02, \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WzYah5mDSyp",
        "outputId": "1dfe5b6a-4699-48ef-d813-0a804e47b264"
      },
      "outputs": [],
      "source": [
        "if not local_mode:\n",
        "    %pip install pytorch_pretrained_bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpqTOfkfBJZz",
        "outputId": "6750740c-4439-4a73-f8f7-8a7b82fcbeb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(301, 72)\n",
              "      (segment_embeddings): Embedding(2, 72)\n",
              "      (age_embeddings): Embedding(1322, 72)\n",
              "      (posi_embeddings): Embedding(256, 72)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=72, out_features=72, bias=True)\n",
              "              (key): Linear(in_features=72, out_features=72, bias=True)\n",
              "              (value): Linear(in_features=72, out_features=72, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=72, out_features=72, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=72, out_features=512, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=512, out_features=72, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=72, out_features=72, bias=True)\n",
              "              (key): Linear(in_features=72, out_features=72, bias=True)\n",
              "              (value): Linear(in_features=72, out_features=72, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=72, out_features=72, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=72, out_features=512, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=512, out_features=72, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=72, out_features=72, bias=True)\n",
              "              (key): Linear(in_features=72, out_features=72, bias=True)\n",
              "              (value): Linear(in_features=72, out_features=72, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=72, out_features=72, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=72, out_features=512, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=512, out_features=72, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=72, out_features=72, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=72, out_features=72, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "      )\n",
              "      (decoder): Linear(in_features=72, out_features=301, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import models\n",
        "import pytorch_pretrained_bert as Bert\n",
        "import sklearn.metrics as skm\n",
        "\n",
        "import models.BertConfig as BertConfig\n",
        "import models.MLM as MLM\n",
        "from models.optimizer import adam\n",
        "\n",
        "conf = BertConfig.BertConfig(model_config)\n",
        "model = MLM.BertForMaskedLM(conf)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3UBaFLSBJZz",
        "outputId": "c9335e90-5f2d-4822-cccc-b5de26f0ef8f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ],
      "source": [
        "model = model.to(global_params['device'])\n",
        "optim = adam(params=list(model.named_parameters()), config=optim_param)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Ra0pTkvhBJZ0"
      },
      "outputs": [],
      "source": [
        "def cal_acc(label, pred):\n",
        "    logs = nn.LogSoftmax()\n",
        "    \n",
        "    label = label.cpu().numpy()\n",
        "\n",
        "    # Exclude tokens that were not masked\n",
        "    ind = np.where(label != -1)[0]\n",
        "\n",
        "    # Get True label\n",
        "    truelabel = label[ind]\n",
        "\n",
        "    # Get the true prediction\n",
        "    truepred = pred.detach().cpu().numpy()\n",
        "    truepred = truepred[ind]\n",
        "    truepred = logs(torch.tensor(truepred))\n",
        "    outs = [np.argmax(pred_x) for pred_x in truepred.numpy()]\n",
        "\n",
        "    # Calculate precision\n",
        "    precision = skm.precision_score(truelabel, outs, average='micro')\n",
        "\n",
        "    return precision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "uhPjyDWwBJZ1"
      },
      "outputs": [],
      "source": [
        "def train(e, loader):\n",
        "    tr_loss = 0\n",
        "    temp_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    cnt = 0\n",
        "    start = time.time()\n",
        "\n",
        "    for step, batch in enumerate(loader):\n",
        "        cnt += 1\n",
        "        batch = tuple(t.to(global_params['device']) for t in batch)\n",
        "        token_ids, age_ids, posi_ids, segment_ids, attMask, masked_label = batch\n",
        "\n",
        "        # Call Bert Model\n",
        "        loss, pred, label= model(token_ids, age_ids, segment_ids, posi_ids,attention_mask=attMask, masked_lm_labels=masked_label)\n",
        "\n",
        "        if global_params['gradient_accumulation_steps'] > 1:\n",
        "            loss = loss/global_params['gradient_accumulation_steps']\n",
        "            \n",
        "        loss.backward()\n",
        "\n",
        "        temp_loss += loss.item()\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        # TBD: Remove? They are not used anywhere\n",
        "        nb_tr_examples += token_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "        if step % 200 == 0:\n",
        "            print(\"epoch: {}\\t| cnt: {}\\t|Loss: {}\\t| precision: {:.4f}\\t| time: {:.2f}\".format(\n",
        "                e, cnt, temp_loss/200, cal_acc(label, pred), time.time()-start))\n",
        "            temp_loss = 0\n",
        "            start = time.time()\n",
        "\n",
        "        if (step + 1) % global_params['gradient_accumulation_steps'] == 0:\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "    print(\"** ** * Saving fine - tuned model ** ** * \")\n",
        "    model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
        "    \n",
        "    utils.create_folder(file_config['model_path'])\n",
        "    output_model_file = os.path.join(file_config['model_path'], file_config['model_name'] +'.pt')\n",
        "    torch.save(model_to_save.state_dict(), output_model_file)\n",
        "        \n",
        "    cost = time.time() - start\n",
        "    return tr_loss, cost"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train MLM model\n",
        "Train model, get token embeddings and save to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o-Vx6GbZBJZ1",
        "outputId": "b0ad21a1-27fc-40a9-91eb-d4c352cd5b56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch\tloss\ttime\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\birhanu.digafe\\AppData\\Local\\Temp\\ipykernel_15848\\939496931.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  truepred = logs(torch.tensor(truepred))\n",
            "c:\\Python39\\lib\\site-packages\\pytorch_pretrained_bert\\optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:1420.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0\t| cnt: 1\t|Loss: 0.002889216423034668\t| precision: 0.0019\t| time: 9.65\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\birhanu.digafe\\AppData\\Local\\Temp\\ipykernel_15848\\939496931.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  truepred = logs(torch.tensor(truepred))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1\t| cnt: 1\t|Loss: 0.0026372926235198975\t| precision: 0.3666\t| time: 9.21\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\birhanu.digafe\\AppData\\Local\\Temp\\ipykernel_15848\\939496931.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  truepred = logs(torch.tensor(truepred))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 2\t| cnt: 1\t|Loss: 0.002478182077407837\t| precision: 0.3714\t| time: 11.95\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\birhanu.digafe\\AppData\\Local\\Temp\\ipykernel_15848\\939496931.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  truepred = logs(torch.tensor(truepred))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 3\t| cnt: 1\t|Loss: 0.002415282726287842\t| precision: 0.3713\t| time: 10.69\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\birhanu.digafe\\AppData\\Local\\Temp\\ipykernel_15848\\939496931.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  truepred = logs(torch.tensor(truepred))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 4\t| cnt: 1\t|Loss: 0.0023393056392669678\t| precision: 0.3846\t| time: 10.99\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        }
      ],
      "source": [
        "f = open(os.path.join(file_config['model_path'],file_config['log_file_name']), \"w\")\n",
        "print('{}\\t{}\\t{}\\n'.format('epoch', 'loss', 'time'))\n",
        "\n",
        "model.train(True)\n",
        "\n",
        "for e in range(global_params[\"num_epochs\"]):\n",
        "    loss, time_cost = train(e, train_loader)\n",
        "    data_len = len(train_loader)\n",
        "    loss = loss/data_len\n",
        "\n",
        "    f.write('{}\\t{}\\t{}\\n'.format(e, loss, time_cost))\n",
        "f.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Reload the model from disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_model_file = os.path.join(file_config['model_path'], file_config['model_name']) + '.pt'\n",
        "model.eval()\n",
        "\n",
        "data = torch.load(output_model_file, map_location='cpu')\n",
        "print(data.keys())\n",
        "word_embedding = data['bert.embeddings.word_embeddings.weight']\n",
        "print(word_embedding.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Map the word embedding to the original vocab in 2D space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import mpld3\n",
        "\n",
        "# This does not work when wrapped inside a function\n",
        "# Reduce dimensions 301 -> 2\n",
        "data = word_embedding\n",
        "pca = PCA(n_components=2).fit_transform(data)\n",
        "kmeans = KMeans(n_clusters=20, n_init=1)\n",
        "kmeans.fit(pca)\n",
        "\n",
        "# Obtain labels for each point to use as a color\n",
        "x = pca[:, 0]\n",
        "y = pca[:, 1]\n",
        "c = kmeans.predict(np.c_[x, y])\n",
        "\n",
        "# plot\n",
        "fig = plt.figure( figsize=(15,8), facecolor=\"white\", edgecolor='white')\n",
        "ax = fig.add_subplot()\n",
        "scatter = ax.scatter(x, y, c=c, cmap='rainbow')\n",
        "ax.set_facecolor(\"white\")\n",
        "plt.rcParams['axes.facecolor'] = 'gray'\n",
        "\n",
        "# Create the tooltip\n",
        "labels = []\n",
        "for i in range(5, len(x)):\n",
        "    code = conditionsVocab[\"idx2token\"][i]\n",
        "    label = condition_codes[condition_codes[\"condition\"] == str(code)][\"condition_name\"].values[0]\n",
        "    labels.append(label)\n",
        "\n",
        "tooltip = mpld3.plugins.PointLabelTooltip(scatter, labels=labels)\n",
        "\n",
        "# Add the tooltip to the plot\n",
        "mpld3.plugins.connect(fig, tooltip )\n",
        "\n",
        "# Display the plot\n",
        "mpld3.display()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
