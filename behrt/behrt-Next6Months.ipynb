{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VDIyndGVBJZh"
      },
      "source": [
        "### Task 3: Next 6-months prediction"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qtTLL2DrBJZk"
      },
      "source": [
        "#### Fine tunning\n",
        "\n",
        "BERT generates word embeddings for the vocabulary words included in the corpus. In other words, each word or medical diganoses in our case, is mapped to a vector. In contrast to Word2Vec, BERT generates code that captures the local context of words and therefore provides a better representation of the word.\n",
        "\n",
        "MLM (Masked Language Model) is used for optimization, which we already performed on the 2nd task. In this step, we will add a task to predict the diagnosis codes after 6-months from a randomly selected visit date. This new task will be trained and the word embeddings will be fine tuned as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "local_mode = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCUA0c8cBgHD",
        "outputId": "9e8d6d80-f871-4a52-cc9e-fabf398b38eb"
      },
      "outputs": [],
      "source": [
        "if not local_mode:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "\n",
        "    !cp -r gdrive/MyDrive/behrt/data data/\n",
        "    !cp -r gdrive/MyDrive/behrt/commons commons/\n",
        "    !cp -r gdrive/MyDrive/behrt/models models/"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### File and model paramters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "IayjuaWgBJZm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import commons.utils as utils\n",
        "from models import optimizer\n",
        "from torch.utils.data import DataLoader\n",
        "import pytorch_pretrained_bert as Bert\n",
        "\n",
        "# set random seed for reproducibility\n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "os.environ['PYTHONASHSEED'] = str(seed)\n",
        "\n",
        "global_params = {\n",
        "    'max_seq_len': 256,\n",
        "    'max_age' : 110,\n",
        "    'age_month' : 12,\n",
        "    'batch_size': 128,\n",
        "    'num_epochs': 5,\n",
        "    'min_visit': 5,\n",
        "    'gradient_accumulation_steps': 1,\n",
        "    'training_sample' : 2000,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "}\n",
        "\n",
        "optim_config = {\n",
        "    'lr': 3e-5,\n",
        "    'warmup_proportion': 0.1,\n",
        "    'weight_decay': 0.01\n",
        "}\n",
        "\n",
        "file_config = {\n",
        "    'vocab': ('C:/Birhanu/Education/UIL/cs598/Final/data/' if local_mode else 'data /') + 'condition_codes.pkl',\n",
        "    'data': ('C:/Birhanu/Education/UIL/cs598/Final/data/' if local_mode else 'data /' ) + 'conditions.pkl',\n",
        "    'ages' : ('C:/Birhanu/Education/UIL/cs598/Final/data/' if local_mode else 'data /' ) + 'ages.pkl',\n",
        "\n",
        "    'model_path': 'C:/Birhanu/Education/UIL/cs598/Final/saved_models/' if local_mode else 'data/',  # where to save model\n",
        "    'model_name': 'next6m-model',  # model name\n",
        "    \n",
        "    'log_file_name': 'next6m-log',  # log path\n",
        "}\n",
        "\n",
        "# MLM pretrained model path\n",
        "pretrainModel = 'C:/Birhanu/Education/UIL/cs598/Final/saved_models/mlm128.pt'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not local_mode:\n",
        "  %pip install pytorch_pretrained_bert\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "AkM2z7YqH0K6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "print(global_params[\"device\"])\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt_kVGeZBJZo"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf_4wsLcBJZo",
        "outputId": "1f83167d-5f79-4b65-88d9-ff376d10a36b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conditions vocab file: C:/Birhanu/Education/UIL/cs598/Final/data/condition_codes.pkl\n",
            "      pid                                              visit  \\\n",
            "0  176102  [35211387, 35207924, SEP, 1569634, SEP, 157606...   \n",
            "1  176104  [35208969, SEP, 35208968, 35208969, SEP, 35208...   \n",
            "2  176106  [35207966, SEP, 45591555, SEP, 35208968, 15706...   \n",
            "3  176107  [1569446, SEP, 1574193, 35209007, 1571058, SEP...   \n",
            "4  176108  [35208190, SEP, 35208481, SEP, 1567866, SEP, 1...   \n",
            "\n",
            "                                                 age                     label  \n",
            "0  [19, 19, 19, 21, 21, 21, 21, 22, 22, 22, 22, 2...            [1568524, SEP]  \n",
            "1  [51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 5...            [1568344, SEP]  \n",
            "2  [37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 3...  [35208968, 1570694, SEP]  \n",
            "3  [33, 33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 3...            [1570790, SEP]  \n",
            "4  [64, 64, 65, 65, 66, 66, 66, 66, 66, 66, 66, 6...            [1569558, SEP]  \n"
          ]
        }
      ],
      "source": [
        "# Load conditions codes (word vocabs)\n",
        "print(f\"Conditions vocab file: {file_config['vocab']}\")\n",
        "vocab_conditions = utils.get_codes_vocab(file_config[\"vocab\"])\n",
        "code2idx = vocab_conditions[\"token2idx\"]\n",
        "\n",
        "# This fails when resolving PAD and UNK tokens\n",
        "#code2idx = utils.remove_system_codes_from_token_dict(code2idx)\n",
        "\n",
        "# Create age vocab\n",
        "vocab_age = utils.age_vocab(global_params[\"max_age\"], global_params[\"age_month\"])\n",
        "age2idx = vocab_age[0]\n",
        "\n",
        "# Load data\n",
        "data_conditions = utils.load_data(file_config[\"data\"], sample_size=global_params[\"training_sample\"])\n",
        "data_age_seqs = utils.load_data(file_config[\"ages\"], sample_size=global_params[\"training_sample\"])\n",
        "\n",
        "# Split data into train, validation, and test\n",
        "train_data, test_data = utils.split_data(data_conditions, data_age_seqs, train_ratio=0.8, min_size=3)\n",
        "print(train_data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1572199',\n",
              " 'SEP',\n",
              " '35207924',\n",
              " 'SEP',\n",
              " '35209141',\n",
              " 'SEP',\n",
              " '45534429',\n",
              " '1572201',\n",
              " '45606796',\n",
              " '45534435',\n",
              " '1570565',\n",
              " '1570359',\n",
              " 'SEP']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_conditions.iloc[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['78', '78', '78', '78', '79', '79', '79', '79', '79', '79', '79', '79', '79']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_age_seqs.iloc[0][1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_config = {\n",
        "    # number of disease + symbols for word embedding\n",
        "    'vocab_size': len(vocab_conditions['token2idx'].keys()),\n",
        "    'hidden_size': 144,  # word embedding and seg embedding hidden size\n",
        "    'seg_vocab_size': 2,  # number of vocab for seg embedding\n",
        "    # number of vocab for age embedding\n",
        "    'age_vocab_size': len(vocab_age[0].keys()),\n",
        "    # maximum number of tokens\n",
        "    'max_position_embedding': global_params['max_seq_len'],\n",
        "    'hidden_dropout_prob': 0.2,  # dropout rate\n",
        "    'num_hidden_layers': 6,  # number of multi-head attention layers required\n",
        "    'num_attention_heads': 12,  # number of attention heads\n",
        "    'attention_probs_dropout_prob': 0.22,  # multi-head attention dropout rate\n",
        "    # the size of the \"intermediate\" layer in the transformer encoder\n",
        "    'intermediate_size': 512,\n",
        "    # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
        "    'hidden_act': 'gelu',\n",
        "    'initializer_range': 0.02,  # parameter weight initializer range\n",
        "}\n",
        "\n",
        "feature_dict = {\n",
        "    'age': True,\n",
        "    'seg': True,\n",
        "    'posi': True\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NextVisit(Dataset):\n",
        "    def __init__(self, token2idx, diag2idx, age2idx, dataframe, max_len, max_age=110, min_visit=5):\n",
        "        # dataframe preproecssing\n",
        "        # filter out the patient with number of visits less than min_visit\n",
        "        self.vocab = token2idx\n",
        "        self.label_vocab = diag2idx\n",
        "        self.max_len = max_len\n",
        "\n",
        "        self.code = dataframe.visit\n",
        "        self.age = dataframe.age\n",
        "        self.label = dataframe.label\n",
        "        self.patid = dataframe.pid\n",
        "\n",
        "        self.age2idx = age2idx\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        return: age, code, position, segmentation, mask, label\n",
        "        \"\"\"\n",
        "        # cut data\n",
        "        age = self.age[index]\n",
        "        code = self.code[index]\n",
        "        label = self.label[index]\n",
        "        patid = self.patid[index]\n",
        "\n",
        "        # extract data\n",
        "        age = age[(-self.max_len+1):]\n",
        "        code = code[(-self.max_len+1):]\n",
        "\n",
        "        # avoid data cut with first element to be 'SEP'\n",
        "        if code[0] != 'SEP':\n",
        "            code = np.append(np.array(['CLS']), code)\n",
        "            age = np.append(np.array(age[0]), age)\n",
        "        else:\n",
        "            code[0] = 'CLS'\n",
        "\n",
        "        # mask 0:len(code) to 1, padding to be 0\n",
        "        mask = np.ones(self.max_len)\n",
        "        mask[len(code):] = 0\n",
        "\n",
        "        # pad age sequence and code sequence\n",
        "        age = utils.seq_padding(age, self.max_len, token2idx=self.age2idx, unkown=False)\n",
        "\n",
        "        tokens, code = utils.code2index(code, self.vocab)\n",
        "        _, label = utils.code2index(label, self.label_vocab)\n",
        "\n",
        "        # get position code and segment code\n",
        "        tokens = utils.seq_padding(tokens, self.max_len)\n",
        "        position = utils.position_idx(tokens)\n",
        "        segment = utils.index_seg(tokens)\n",
        "\n",
        "        # pad code and label\n",
        "        code = utils.seq_padding(code, self.max_len, symbol=self.vocab['PAD'], unkown=False)\n",
        "        label = utils.seq_padding(label, self.max_len, symbol=-1)\n",
        "\n",
        "        return torch.LongTensor(age), torch.LongTensor(code), torch.LongTensor(position), torch.LongTensor(segment), \\\n",
        "            torch.LongTensor(mask), torch.LongTensor(\n",
        "                label), torch.LongTensor([int(patid)])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.code)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BertConfig(Bert.modeling.BertConfig):\n",
        "    def __init__(self, config):\n",
        "        super(BertConfig, self).__init__(\n",
        "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
        "            hidden_size=config['hidden_size'],\n",
        "            num_hidden_layers=config.get('num_hidden_layers'),\n",
        "            num_attention_heads=config.get('num_attention_heads'),\n",
        "            intermediate_size=config.get('intermediate_size'),\n",
        "            hidden_act=config.get('hidden_act'),\n",
        "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
        "            attention_probs_dropout_prob=config.get(\n",
        "                'attention_probs_dropout_prob'),\n",
        "            max_position_embeddings=config.get('max_position_embedding'),\n",
        "            initializer_range=config.get('initializer_range'),\n",
        "        )\n",
        "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
        "        self.age_vocab_size = config.get('age_vocab_size')\n",
        "\n",
        "\n",
        "class BertEmbeddings(nn.Module):\n",
        "    \"\"\"Construct the embeddings from word, segment, age\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, feature_dict):\n",
        "        super(BertEmbeddings, self).__init__()\n",
        "        self.feature_dict = feature_dict\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(\n",
        "            config.vocab_size, config.hidden_size)\n",
        "        self.segment_embeddings = nn.Embedding(\n",
        "            config.seg_vocab_size, config.hidden_size)\n",
        "        self.age_embeddings = nn.Embedding(\n",
        "            config.age_vocab_size, config.hidden_size)\n",
        "        self.posi_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size).\\\n",
        "            from_pretrained(embeddings=self._init_posi_embedding(\n",
        "                config.max_position_embeddings, config.hidden_size))\n",
        "\n",
        "        self.LayerNorm = Bert.modeling.BertLayerNorm(\n",
        "            config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, word_ids, age_ids=None, seg_ids=None, posi_ids=None, age=True):\n",
        "        if seg_ids is None:\n",
        "            seg_ids = torch.zeros_like(word_ids)\n",
        "        if age_ids is None:\n",
        "            age_ids = torch.zeros_like(word_ids)\n",
        "        if posi_ids is None:\n",
        "            posi_ids = torch.zeros_like(word_ids)\n",
        "\n",
        "        word_embed = self.word_embeddings(word_ids)\n",
        "        segment_embed = self.segment_embeddings(seg_ids)\n",
        "        age_embed = self.age_embeddings(age_ids)\n",
        "        posi_embeddings = self.posi_embeddings(posi_ids)\n",
        "\n",
        "        embeddings = word_embed\n",
        "\n",
        "        if self.feature_dict['age']:\n",
        "            embeddings = embeddings + age_embed\n",
        "        if self.feature_dict['seg']:\n",
        "            embeddings = embeddings + segment_embed\n",
        "        if self.feature_dict['posi']:\n",
        "            embeddings = embeddings + posi_embeddings\n",
        "\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "    def _init_posi_embedding(self, max_position_embedding, hidden_size):\n",
        "        def even_code(pos, idx):\n",
        "            return np.sin(pos/(10000**(2*idx/hidden_size)))\n",
        "\n",
        "        def odd_code(pos, idx):\n",
        "            return np.cos(pos/(10000**(2*idx/hidden_size)))\n",
        "\n",
        "        # initialize position embedding table\n",
        "        lookup_table = np.zeros(\n",
        "            (max_position_embedding, hidden_size), dtype=np.float32)\n",
        "\n",
        "        # reset table parameters with hard encoding\n",
        "        # set even dimension\n",
        "        for pos in range(max_position_embedding):\n",
        "            for idx in np.arange(0, hidden_size, step=2):\n",
        "                lookup_table[pos, idx] = even_code(pos, idx)\n",
        "        # set odd dimension\n",
        "        for pos in range(max_position_embedding):\n",
        "            for idx in np.arange(1, hidden_size, step=2):\n",
        "                lookup_table[pos, idx] = odd_code(pos, idx)\n",
        "\n",
        "        return torch.tensor(lookup_table)\n",
        "\n",
        "\n",
        "class BertModel(Bert.modeling.BertPreTrainedModel):\n",
        "    def __init__(self, config, feature_dict):\n",
        "        super(BertModel, self).__init__(config)\n",
        "        self.embeddings = BertEmbeddings(config, feature_dict)\n",
        "        self.encoder = Bert.modeling.BertEncoder(config=config)\n",
        "        self.pooler = Bert.modeling.BertPooler(config)\n",
        "        self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, age_ids=None, seg_ids=None, posi_ids=None, attention_mask=None, output_all_encoded_layers=True):\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones_like(input_ids)\n",
        "        if age_ids is None:\n",
        "            age_ids = torch.zeros_like(input_ids)\n",
        "        if seg_ids is None:\n",
        "            seg_ids = torch.zeros_like(input_ids)\n",
        "        if posi_ids is None:\n",
        "            posi_ids = torch.zeros_like(input_ids)\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "\n",
        "        embedding_output = self.embeddings(\n",
        "            input_ids, age_ids, seg_ids, posi_ids)\n",
        "        encoded_layers = self.encoder(embedding_output,\n",
        "                                      extended_attention_mask,\n",
        "                                      output_all_encoded_layers=output_all_encoded_layers)\n",
        "        sequence_output = encoded_layers[-1]\n",
        "        pooled_output = self.pooler(sequence_output)\n",
        "        if not output_all_encoded_layers:\n",
        "            encoded_layers = encoded_layers[-1]\n",
        "        return encoded_layers, pooled_output\n",
        "\n",
        "\n",
        "class BertForMultiLabelPrediction(Bert.modeling.BertPreTrainedModel):\n",
        "    def __init__(self, config, num_labels, feature_dict):\n",
        "\n",
        "        super(BertForMultiLabelPrediction, self).__init__(config)\n",
        "        \n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config, feature_dict)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "        self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, age_ids=None, seg_ids=None, posi_ids=None, attention_mask=None, labels=None):\n",
        "        _, pooled_output = self.bert(input_ids, age_ids, seg_ids, posi_ids, attention_mask,\n",
        "                                     output_all_encoded_layers=False)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.MultiLabelSoftMarginLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels),\n",
        "                            labels.view(-1, self.num_labels))\n",
        "            return loss, logits\n",
        "        else:\n",
        "            return logits\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "Dset = NextVisit(token2idx=code2idx, diag2idx=code2idx,\n",
        "                 age2idx=vocab_age, dataframe=train_data, \n",
        "                 max_len=global_params['max_seq_len'])\n",
        "\n",
        "trainload = DataLoader(\n",
        "    dataset=Dset, batch_size=global_params['batch_size'], shuffle=True, num_workers=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "Dset = NextVisit(token2idx=code2idx, diag2idx=code2idx,\n",
        "                 age2idx=vocab_age, dataframe=test_data, max_len=global_params['max_seq_len'])\n",
        "\n",
        "testload = DataLoader(dataset=Dset, batch_size=global_params['batch_size'], shuffle=False, num_workers=3)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of conditions vocab: 301\n",
            "Size of Age vocab: 112\n"
          ]
        }
      ],
      "source": [
        "print(f\"Size of conditions vocab: {len(vocab_conditions['token2idx'])}\")\n",
        "print(f\"Size of Age vocab: {len(vocab_age[0].keys())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3UBaFLSBJZz",
        "outputId": "c9335e90-5f2d-4822-cccc-b5de26f0ef8f"
      },
      "outputs": [],
      "source": [
        "conf = BertConfig(model_config)\n",
        "model = BertForMultiLabelPrediction(conf,  len(vocab_conditions[\"token2idx\"]), feature_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:/Birhanu/Education/UIL/cs598/Final/saved_models/mlm128.pt'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Birhanu\\Education\\UIL\\cs598\\Final\\behrt\\behrt-Next6Months.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Birhanu/Education/UIL/cs598/Final/behrt/behrt-Next6Months.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# load pretrained model and update weights\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Birhanu/Education/UIL/cs598/Final/behrt/behrt-Next6Months.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pretrained_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(pretrainModel)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Birhanu/Education/UIL/cs598/Final/behrt/behrt-Next6Months.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_dict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mstate_dict()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Birhanu/Education/UIL/cs598/Final/behrt/behrt-Next6Months.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# 1. filter out unnecessary keys\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    769\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 771\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    772\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    773\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    774\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    775\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    776\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
            "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 270\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    271\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
            "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Birhanu/Education/UIL/cs598/Final/saved_models/mlm128.pt'"
          ]
        }
      ],
      "source": [
        "# load pretrained model and update weights\n",
        "pretrained_dict = torch.load(pretrainModel)\n",
        "model_dict = model.state_dict()\n",
        "\n",
        "# 1. filter out unnecessary keys\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "\n",
        "# 2. overwrite entries in the existing state dict\n",
        "model_dict.update(pretrained_dict)\n",
        "\n",
        "# 3. load the new state dict\n",
        "model.load_state_dict(model_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ],
      "source": [
        "model = model.to(global_params['device'])\n",
        "optim = optimizer.adam(params=list(\n",
        "    model.named_parameters()), config=optim_config)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "def precision(logits, label):\n",
        "    sig = nn.Sigmoid()\n",
        "    output = sig(logits)\n",
        "    label, output = label.cpu(), output.detach().cpu()\n",
        "    tempprc = average_precision_score(\n",
        "        label.numpy(), output.numpy(), average='samples')\n",
        "    return tempprc, output, label\n",
        "\n",
        "\n",
        "def precision_test(logits, label):\n",
        "    sig = nn.Sigmoid()\n",
        "    output = sig(logits)\n",
        "    tempprc = average_precision_score(\n",
        "        label.numpy(), output.numpy(), average='samples')\n",
        "#     roc = roc_auc_score()\n",
        "    return tempprc, output, label\n",
        "\n",
        "\n",
        "def auroc_test(logits, label):\n",
        "    sig = nn.Sigmoid()\n",
        "    output = sig(logits)\n",
        "    tempprc = roc_auc_score(label.numpy(), output.numpy(), average='samples')\n",
        "#     roc = roc_auc_score()\n",
        "    return tempprc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multi-hot Label Encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiLabelBinarizer(classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,\n",
              "                             15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                             28, 29, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiLabelBinarizer</label><div class=\"sk-toggleable__content\"><pre>MultiLabelBinarizer(classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,\n",
              "                             15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                             28, 29, ...])</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MultiLabelBinarizer(classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,\n",
              "                             15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                             28, 29, ...])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "indexes = list(vocab_conditions[\"token2idx\"].values())\n",
        "\n",
        "mlb = MultiLabelBinarizer(classes=list(indexes))\n",
        "mlb.fit([[each] for each in list(indexes)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(e):\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    temp_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    cnt = 0\n",
        "    for step, batch in enumerate(trainload):\n",
        "        cnt += 1\n",
        "        age_ids, input_ids, posi_ids, segment_ids, attMask, targets, _ = batch\n",
        "        targets = torch.tensor(mlb.transform(\n",
        "            targets.numpy()), dtype=torch.float32)\n",
        "\n",
        "        age_ids = age_ids.to(global_params['device'])\n",
        "        input_ids = input_ids.to(global_params['device'])\n",
        "        posi_ids = posi_ids.to(global_params['device'])\n",
        "        segment_ids = segment_ids.to(global_params['device'])\n",
        "        attMask = attMask.to(global_params['device'])\n",
        "        targets = targets.to(global_params['device'])\n",
        "\n",
        "        loss, logits = model(input_ids, age_ids, segment_ids,\n",
        "                             posi_ids, attention_mask=attMask, labels=targets)\n",
        "\n",
        "        if global_params['gradient_accumulation_steps'] > 1:\n",
        "            loss = loss/global_params['gradient_accumulation_steps']\n",
        "        loss.backward()\n",
        "\n",
        "        temp_loss += loss.item()\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "        if step % 2000 == 0:\n",
        "            prec, a, b = precision(logits, targets)\n",
        "            print(\"epoch: {}\\t| Cnt: {}\\t| Loss: {}\\t| precision: {}\".format(\n",
        "                e, cnt, temp_loss/2000, prec))\n",
        "            temp_loss = 0\n",
        "\n",
        "        if (step + 1) % global_params['gradient_accumulation_steps'] == 0:\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "\n",
        "def evaluation():\n",
        "    model.eval()\n",
        "    y = []\n",
        "    y_label = []\n",
        "    for step, batch in enumerate(testload):\n",
        "        model.eval()\n",
        "        age_ids, input_ids, posi_ids, segment_ids, attMask, targets, _ = batch\n",
        "        targets = torch.tensor(mlb.transform(\n",
        "            targets.numpy()), dtype=torch.float32)\n",
        "\n",
        "        age_ids = age_ids.to(global_params['device'])\n",
        "        input_ids = input_ids.to(global_params['device'])\n",
        "        posi_ids = posi_ids.to(global_params['device'])\n",
        "        segment_ids = segment_ids.to(global_params['device'])\n",
        "        attMask = attMask.to(global_params['device'])\n",
        "        targets = targets.to(global_params['device'])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            loss, logits = model(input_ids, age_ids, segment_ids,\n",
        "                                 posi_ids, attention_mask=attMask, labels=targets)\n",
        "        logits = logits.cpu()\n",
        "        targets = targets.cpu()\n",
        "\n",
        "        y_label.append(targets)\n",
        "        y.append(logits)\n",
        "\n",
        "    y_label = torch.cat(y_label, dim=0)\n",
        "    y = torch.cat(y, dim=0)\n",
        "\n",
        "    tempprc, output, label = precision_test(y, y_label)\n",
        "    auroc = auroc_test(y, y_label)\n",
        "    return tempprc, auroc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "optim_config = {\n",
        "    'lr': 3e-6,\n",
        "    'warmup_proportion': 0.1\n",
        "}\n",
        "optim = optimizer.adam(params=list(\n",
        "    model.named_parameters()), config=optim_config)\n",
        "\n",
        "best_pre = 0.512\n",
        "for e in range(50):\n",
        "    train(e)\n",
        "    auc, roc = evaluation()\n",
        "    if auc > best_pre:\n",
        "        # Save a trained model\n",
        "        print(\"** ** * Saving fine - tuned model ** ** * \")\n",
        "        model_to_save = model.module if hasattr(\n",
        "            model, 'module') else model  # Only save the model it-self\n",
        "        output_model_file = os.path.join(\n",
        "            global_params['output_dir'], global_params['best_name'])\n",
        "        \n",
        "        utils.create_folder(global_params['output_dir'])\n",
        "        if global_params['save_model']:\n",
        "            torch.save(model_to_save.state_dict(), output_model_file)\n",
        "        best_pre = auc\n",
        "    print('precision : {}, auroc: {},'.format(auc, roc))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
