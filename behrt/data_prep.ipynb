{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing input data\n",
    "The input data is a synthetic data obtained from medisyn.ai and follows the OMOP/CMD format. We downloaded the Outpatient data files. The following files are used:\n",
    "- persons.csv\n",
    "- visit_occurrence.csv\n",
    "- conditions_occurrence.csv\n",
    "\n",
    "The goal of the pre-processing process is to produce three files that will be fed for BERT embedding:\n",
    "- conditions.pkl: Contains a record per patient that has the conditions (medical codes) for each visit.\n",
    "- ages.pkl: The person's age at each of the conditions observed. \n",
    "- condition_codes: List of condition codes to build codes vocanb\n",
    "\n",
    "Following BERT data format, each person's data will start with \"CLS\" and each visit is separated by \"SEP\".\n",
    "\n",
    "Note: The produced files will be saved in pickle format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "DATA_PATH = 'C:/Birhanu/Education/UIL/cs598/Final/data/'\n",
    "FREQ_THRESHOLD = 3000\n",
    "MIN_VISITS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2Pickle(in_file_name,\n",
    "               usecols:list=None, \n",
    "               dtypes:list=None, \n",
    "               converters:list=None, \n",
    "               column_mapper:list=None,\n",
    "               out_filename:str=None,\n",
    "               delimiter = \",\"):\n",
    "    \"\"\"\n",
    "    Converts a csv file to a pickle file.\n",
    "    \n",
    "    Parameters:\n",
    "        in_file_name (str): The name of the csv file to be converted.\n",
    "        usecols (list): A list of columns to be used from the dataframe. Drop the rest.\n",
    "        dtypes (dict): A dictionary of column names and their data types.\n",
    "        converters (dict): A dictionary of column names and their converters.\n",
    "        column_mapper (dict): A dictionary of column names and their new names.\n",
    "    \"\"\"\n",
    "    if (out_filename is None):\n",
    "        out_filename = in_file_name.replace('.csv', '.pkl')\n",
    "\n",
    "    csv = pd.read_csv(\n",
    "        in_file_name,\n",
    "        delimiter=delimiter,\n",
    "        usecols=usecols,\n",
    "        dtype=dtypes,\n",
    "        converters=converters\n",
    "    )\n",
    "\n",
    "    if (column_mapper is not None and len(column_mapper) > 0):\n",
    "        csv.rename(columns=column_mapper, inplace=True)\n",
    "\n",
    "    csv.to_pickle(out_filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the patient.csv to patient.pkl file format.\n",
    "Only keep the columns needed for this project:\n",
    "- person_id -> pid\n",
    "- gender_concept_id -> gender\n",
    "- birth_datetime -> dob\n",
    "- ethnicity_concept_id -> ethnicity\n",
    "\n",
    "**Time esitmate:** 1 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Convert the person data file to a pickle file\n",
    "person_columns = [\n",
    "    'person_id', \n",
    "    'gender_concept_id',\n",
    "    'birth_datetime',\n",
    "    'ethnicity_concept_id'\n",
    "]\n",
    " \n",
    "person_column_mapper = {\n",
    "    'person_id'             : 'pid',\n",
    "    'gender_concept_id'     : 'gender',\n",
    "    'birth_datetime'        : 'dob',\n",
    "    'ethnicity_concept_id'  : 'ethnicity'\n",
    "}\n",
    "\n",
    "person_dtypes = {\n",
    "    'person_id'             : 'str',\n",
    "    'gender_concept_id'     : 'str',\n",
    "    'ethnicity_concept_id'  : 'str',\n",
    "}\n",
    "\n",
    "person_converters = {\n",
    "    'date_of_birth': lambda x: pd.to_datetime(x, format='%Y-%m-%d hh:mm:ss') \n",
    "}\n",
    "\n",
    "csv2Pickle(in_file_name=DATA_PATH + 'person.csv', \n",
    "           usecols=person_columns, \n",
    "           dtypes=person_dtypes,\n",
    "           converters=person_converters, \n",
    "           column_mapper=person_column_mapper,\n",
    "           out_filename=DATA_PATH + 'person.pkl'\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the visit_occurrence.csv to visits.pkl file format.\n",
    "Only keep the columns needed for this project:\n",
    "- visit_occurrence_id -> vid\n",
    "- person_id -> pid\n",
    "- visit_start_date -> start_date\n",
    "\n",
    "**Time estimates:** 8:40min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the visits data file to a pickle file\n",
    "visit_columns = [\n",
    "    'visit_occurrence_id',\n",
    "    'person_id',\n",
    "    'visit_start_date'\n",
    "]\n",
    " \n",
    "visit_column_mapper = {\n",
    "    'visit_occurrence_id'   : 'vid',\n",
    "    'person_id'             : 'pid',\n",
    "    'visit_start_date'      : 'visit_date'\n",
    "}\n",
    "\n",
    "visit_dtypes = {\n",
    "    'visit_occurrence_id'       : 'str',\n",
    "    'person_id'                 : 'str',\n",
    "}\n",
    "\n",
    "visit_converters = {\n",
    "    'visit_start_date': lambda x: pd.to_datetime(x, format='%Y-%m-%d')\n",
    "}\n",
    "\n",
    "csv2Pickle(in_file_name=DATA_PATH + 'visit_occurrence.csv', \n",
    "           usecols=visit_columns,\n",
    "           dtypes=visit_dtypes,\n",
    "           converters=visit_converters,\n",
    "           column_mapper=visit_column_mapper,\n",
    "           out_filename=DATA_PATH + 'visit.pkl'\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the condition_occurrence.csv to condition_visit.pkl file format.\n",
    "Only keep the columns needed for this project:\n",
    "- person_id -> pid\n",
    "- condition_start_date -> event_date\n",
    "- condition_concept_id -> condition\n",
    "\n",
    "**Time estimate**: 13 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the conditions occurrence data file to a pickle file\n",
    "condition_columns = [\n",
    "    'person_id',\n",
    "    'visit_occurrence_id',\n",
    "    'condition_start_date',\n",
    "    'condition_concept_id',\n",
    "]\n",
    " \n",
    "condition_column_mapper = {\n",
    "    'person_id'                 : 'pid',\n",
    "    'visit_occurrence_id'       : 'vid',\n",
    "    'condition_start_date'      : 'event_date',\n",
    "    'condition_concept_id'      : 'condition'\n",
    "}\n",
    "\n",
    "condition_dtypes = {\n",
    "    'person_id'                 : 'str',\n",
    "    'visit_occurrence_id'       : 'str',\n",
    "    'condition_concept_id'      : 'str',\n",
    "}\n",
    "\n",
    "condition_converters = {\n",
    "    'condition_start_date'      : lambda x: pd.to_datetime(x, format='%Y-%m-%d')\n",
    "}\n",
    "\n",
    "csv2Pickle(in_file_name=DATA_PATH + 'condition_occurrence.csv',\n",
    "           usecols=condition_columns,\n",
    "           dtypes=condition_dtypes,\n",
    "           column_mapper=condition_column_mapper,\n",
    "           converters=condition_converters,\n",
    "           out_filename=DATA_PATH + 'condition_visit.pkl'\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process the concepts file\n",
    "\n",
    "Only keep the columns needed for this project:\n",
    "- concept_id\n",
    "- domain_id \n",
    "- concept_name\n",
    "\n",
    "**Time estimate**: 1 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the concepts file to pickle format\n",
    "concept_columns = [\n",
    "    'concept_id',\n",
    "    'concept_name',\n",
    "    'domain_id'\n",
    "]\n",
    "\n",
    "concept_column_mapper = {\n",
    "    'concept_id': 'concept_id',\n",
    "    'concept_name': 'concept_name',\n",
    "    'domain_id': 'domain_id'\n",
    "}\n",
    "\n",
    "concept_dtypes = {\n",
    "    'concept_id': 'str',\n",
    "    'concept_name': 'str',\n",
    "    'domain_id' : 'str'\n",
    "}\n",
    "\n",
    "concept_converters = None\n",
    "\n",
    "csv2Pickle(in_file_name=DATA_PATH + 'CONCEPT.csv',\n",
    "           usecols=concept_columns,\n",
    "           dtypes=concept_dtypes,\n",
    "           column_mapper=concept_column_mapper,\n",
    "           converters=concept_converters,\n",
    "           out_filename=DATA_PATH + 'concept.pkl',\n",
    "           delimiter='\\t'\n",
    "           )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the conditions dataframe\n",
    "In this step we process the data frame to remove infrequent conditions, group data by the person id and produce the visit sequence and conditions for each visit.\n",
    "\n",
    "Inputs: \n",
    "    - person.pkl: Persons files after the uncessary columns have been removed.\n",
    "    - condition_visit.pkl - Persons files after the uncessary columns have been removed.\n",
    "\n",
    "- demographics = [pid, gender, dob, ethnicity]\n",
    "- conditions  =  [pid, eventDate, codes = [conditions] ]\n",
    "\n",
    "**Time estimates:** 3 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visits sized reduced by due number of visits (10): -70527\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of occurrences of each condition in the dataset\n",
    "demographics = pd.read_pickle(DATA_PATH + 'person.pkl')\n",
    "visits = pd.read_pickle(DATA_PATH + 'visit.pkl')\n",
    "conditions = pd.read_pickle(DATA_PATH + 'condition_visit.pkl')\n",
    "\n",
    "# Remove patients with less than min visit\n",
    "initial_vists = visits.shape[0]\n",
    "\n",
    "visit_counts = visits.groupby('pid').size().reset_index(name='visit_counts')\n",
    "selected_pids = visit_counts[visit_counts['visit_counts'] >= MIN_VISITS].reset_index(drop=True)\n",
    "visits = visits[visits['pid'].isin(selected_pids['pid'])]\n",
    "print(f\"Visits sized reduced by due number of visits ({MIN_VISITS}): {visits.shape[0] - initial_vists}\")\n",
    "\n",
    "# Get the frequency count of each condition across the dataset\n",
    "freq_conditions = conditions.groupby(['condition']).size().reset_index(name='counts')\n",
    "\n",
    "# Keep only the conditions that occur more than FREQ_THRESHOLD (3000) times\n",
    "freq_conditions = freq_conditions[freq_conditions['counts'] >= FREQ_THRESHOLD].reset_index(drop=True)\n",
    "assert freq_conditions[freq_conditions['condition']==\"10851\"].counts.values[0] == 4323\n",
    "\n",
    "# Filter the conditions data to only include the frequent conditions\n",
    "conditions = conditions[conditions['condition'].isin(freq_conditions['condition'])]\n",
    "\n",
    "# Join visit and conditions with demographics data to add the date of birth\n",
    "conditions = conditions.merge(demographics,  on='pid', how='inner').reset_index(drop=True)\n",
    "conditions = conditions.merge(visits, on=['pid','vid'], how='inner').reset_index(drop=True)\n",
    "\n",
    "# Format the data [pid, dob, visit_date, [condition[]] format, remove duplicates\n",
    "conditions = conditions.groupby(['pid', 'dob', 'visit_date'])['condition'].unique().apply(list).reset_index()\n",
    "\n",
    "# Format conditions as [pid, [[condition]]] format. Rename [condition] to visits\n",
    "#conditions = conditions.groupby(['pid', 'dob', 'visit_date'])['condition'].apply(list).reset_index()\n",
    "conditions.rename(columns={'condition': 'conditions'}, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add age for each visit\n",
    "Compute the patient's age at each visit and add the computed column. \n",
    "Note: Age is calculated in months (total number of full months since birth)\n",
    "\n",
    "Time: 2:30 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add age to the conditions data\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def calculate_age(x):\n",
    "    \"\"\"\n",
    "        Purpose: Calculate the age of a patient at the time of a visit\n",
    "        Parameters: \n",
    "            dob  (datetime): The date of birth of the patient\n",
    "            visit_date (datetime): The date of the visit\n",
    "        Returns:\n",
    "            age (int): The age of the patient in months\n",
    "    \"\"\"\n",
    "    dob = datetime.strptime(x.dob, \"%Y-%m-%d %H:%M:%S\")\n",
    "    visit_date = x[\"visit_date\"].to_pydatetime()\n",
    "\n",
    "    age = relativedelta(visit_date, dob).years * 12 + relativedelta(visit_date, dob).months\n",
    "    return str(age)\n",
    "\n",
    "conditions['age'] = conditions.apply(calculate_age, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(794302, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>dob</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>conditions</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>176103</td>\n",
       "      <td>1937-07-29 00:00:00</td>\n",
       "      <td>1992-12-23</td>\n",
       "      <td>[1570669]</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>176103</td>\n",
       "      <td>1937-07-29 00:00:00</td>\n",
       "      <td>1993-02-09</td>\n",
       "      <td>[1570669]</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>176103</td>\n",
       "      <td>1937-07-29 00:00:00</td>\n",
       "      <td>1993-08-13</td>\n",
       "      <td>[35208969]</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>176103</td>\n",
       "      <td>1937-07-29 00:00:00</td>\n",
       "      <td>1994-08-21</td>\n",
       "      <td>[35208968]</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pid                  dob visit_date  conditions  age\n",
       "50  176103  1937-07-29 00:00:00 1992-12-23   [1570669]  664\n",
       "51  176103  1937-07-29 00:00:00 1993-02-09   [1570669]  666\n",
       "52  176103  1937-07-29 00:00:00 1993-08-13  [35208969]  672\n",
       "53  176103  1937-07-29 00:00:00 1994-08-21  [35208968]  684"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(conditions.shape)\n",
    "conditions[conditions['pid'] == '176103']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the condition names\n",
    "Add the name of the condition (diagnosis name) to the dataframe. It will be used later in the 2D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296, 3)\n",
      "  condition                                     condition_name  counts\n",
      "0     10851  Sprain of joints and ligaments of other parts ...    4323\n",
      "1     11803                Sprain of ligaments of lumbar spine    4293\n",
      "2   1567286                                       Other sepsis    3217\n",
      "3   1567391                Viral infection of unspecified site    4177\n",
      "4   1567392                                    Dermatophytosis    4198\n"
     ]
    }
   ],
   "source": [
    "# Read the clean concepts file\n",
    "concepts = pd.read_pickle(DATA_PATH + 'concept.pkl')\n",
    "concepts = concepts[concepts[\"domain_id\"] == \"Condition\"]\n",
    "\n",
    "freq_conditions = freq_conditions.merge(concepts, how='inner', left_on='condition', right_on='concept_id') \n",
    "freq_conditions = freq_conditions[ ['condition', 'concept_name', 'counts'] ]\n",
    "\n",
    "freq_conditions.rename(columns={'concept_name': 'condition_name'}, inplace=True)\n",
    "freq_conditions.to_pickle(DATA_PATH + 'condition_codes.pkl')\n",
    "\n",
    "print(freq_conditions.shape)\n",
    "print(freq_conditions.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce the condition sequences for each patient and visit\n",
    "\n",
    "The output will follow:[pid, [code1,code2,SEP,code1,code3,code4,...,SEP]]\n",
    "\n",
    "Time estimate: 37 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\birhanu.digafe\\AppData\\Local\\Temp\\ipykernel_26092\\3338795543.py:25: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  seq_codes = conditions.groupby(['pid'])['visit_date', 'conditions'].apply(concat_codes).rename(\"conditions\").reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid                                                      176103\n",
      "conditions    [1570669, SEP, 1570669, SEP, 35208969, SEP, 35...\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "### Format the condition codes as a sequence of conditions: CLS,code1,code2,SEP,code1,code3,code4,...,SEP\n",
    "def concat_codes(x: pd.DataFrame):\n",
    "    \"\"\"\n",
    "        Purpose: Concatenate the condition codes in a visit sequence\n",
    "        Parameters: \n",
    "            visits  (pd.DataFrame): A dataframe of visits\n",
    "        Returns:\n",
    "            seqs (list): A list of unique concatenated condition codes, sorted by code\n",
    "    \"\"\"\n",
    "    sep = 'SEP'\n",
    "    seqs = []\n",
    "\n",
    "    for i in range(len(x['visit_date'])):\n",
    "        conditions = x['conditions'].iloc[i]\n",
    "        if (conditions is not None):\n",
    "            conditions = sorted(conditions)\n",
    "\n",
    "            for c in conditions:\n",
    "                seqs.append(c)\n",
    "\n",
    "            seqs.append(sep)\n",
    " \n",
    "    return seqs\n",
    "\n",
    "seq_codes = conditions.groupby(['pid'])['visit_date', 'conditions'].apply(concat_codes).rename(\"conditions\").reset_index()\n",
    "print(seq_codes.iloc[2])\n",
    "                                                                    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce the age sequence for each person for each condition\n",
    "\n",
    "The formatted output will be: [ [ CLS,age1,age1,SEP,age2,age2,SEP,...] ]\n",
    "One row per person.\n",
    "\n",
    "Time estimate: 1:35 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid                                       176103\n",
      "ages    [664, 664, 666, 666, 672, 672, 684, 684]\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def concat_ages(x: pd.DataFrame):\n",
    "    \"\"\"\n",
    "        Purpose: Concatenate the age of the patient for each condition code.\n",
    "        \n",
    "        Parameters:\n",
    "            x (DataFrame): A DataFrame with the following columns:\n",
    "                pid (str): The patient id\n",
    "                dob (datetime): The date of birth of the patient\n",
    "                event_date (datetime): The date of the condition\n",
    "                visits (list): A list of condition codes\n",
    "        Returns:\n",
    "            seqs (list): A list of concatenated age for each condition code\n",
    "    \n",
    "    \"\"\"\n",
    "    seqs = []\n",
    "\n",
    "    for i in range(len(x['conditions'])):\n",
    "        conditions = x['conditions'].iloc[i]\n",
    "        for _ in conditions:\n",
    "            seqs.append(x['age'].iloc[i])\n",
    "\n",
    "        seqs.append(x['age'].iloc[i])\n",
    "\n",
    "    return seqs\n",
    "\n",
    "seq_ages = conditions.groupby([\"pid\"])[[\"age\", \"visit_date\", \"conditions\"]].apply(concat_ages).rename(\"ages\").reset_index()\n",
    "\n",
    "print(seq_ages.iloc[2])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Validation the codes and ages sequences\n",
    "The seq_codes and seq_ages must have the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(seq_codes[\"conditions\"].iloc[0]) == len(seq_ages[\"ages\"].iloc[0]), \\\n",
    "    \"The number of condition codes and ages do not match\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Write the updated data into the final files\n",
    "Produce files:\n",
    "- \"conditions.pkl\" for conditions\n",
    "- \"ages.pkl\" for ages.pkl\n",
    "- \"condition_codes.pkl\" from freq_conditions\n",
    "\n",
    "Time estimate: 2 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to pickle files\n",
    "\n",
    "seq_codes.to_pickle(DATA_PATH + 'conditions.pkl' )\n",
    "seq_ages.to_pickle(DATA_PATH + 'ages.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
